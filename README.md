# QA Automation API (Pytest + Requests)

Proyecto sencillo para **QA Junior / Backend Junior**: pruebas automatizadas a una API p√∫blica usando `pytest` + `requests`, con configuraci√≥n centralizada y reporte HTML.

## Qu√© vas a practicar
- Validaciones b√°sicas de API: **status codes**, **JSON shape**, datos esperados
- Organizaci√≥n de un proyecto de automation (config, tests, reporting)
- Buenas pr√°cticas m√≠nimas para portfolio (README + bug report template)

## Estructura
- `src/config.py`: configuraci√≥n (base URL, timeout, endpoints)
- `tests/test_posts_api.py`: tests del endpoint `/posts`
- `bug-reports/`: plantilla para reportar bugs
- `pytest.ini`: configuraci√≥n de pytest
- `requirements.txt`: dependencias

## Requisitos
- Python 3.11+ recomendado

## Instalaci√≥n (Windows PowerShell)
Desde la ra√≠z del proyecto:

```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
python -m pip install --upgrade pip
pip install -r requirements.txt
```

## Ejecutar tests

```powershell
pytest
```

## Reporte HTML

```powershell
pytest --html=report.html --self-contained-html
```

Luego abre `report.html` con tu navegador.

## üß™ Testing

Este proyecto incluye pruebas automatizadas de API utilizando `pytest`.

- Se validan c√≥digos de estado (200, 201, 404).
- Se valida la estructura de las respuestas JSON.
- Se incluyen casos felices y casos de error.

### Observaciones QA
Se agreg√≥ un test que valida que el endpoint de posts retorne una lista no vac√≠a.
Actualmente este test falla debido a que el entorno de pruebas no contiene datos iniciales,
lo cual se documenta como comportamiento esperado del entorno y no como un bug funcional.

Para evidenciar el trabajo realizado se generaron:
- Un primer reporte `report.html` con la ejecuci√≥n base de los tests.
- Un segundo reporte (por ejemplo `report_v2.html`) para capturar la ejecuci√≥n del nuevo escenario y comparar resultados.

## Configuraci√≥n por variables de entorno
Pod√©s cambiar el API base sin tocar c√≥digo:

```powershell
$env:BASE_URL="https://jsonplaceholder.typicode.com"
$env:HTTP_TIMEOUT_SECONDS="10"
pytest
```

## Paso a paso (muy detallado) para recrearlo sola

### 1) Crear el proyecto y el entorno virtual
1. Crea una carpeta: `qa-automation-api`
2. Abre la carpeta en Cursor
3. Crea y activa el entorno virtual:

```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
```

### 2) Crear `requirements.txt`
1. Crea un archivo `requirements.txt`
2. Agrega dependencias:
   - `pytest`: framework de test
   - `requests`: cliente HTTP
   - `pytest-html`: reporte en HTML
   - `ruff`: formateo/lint opcional
3. Instala:

```powershell
pip install -r requirements.txt
```

### 3) Crear configuraci√≥n de pytest (`pytest.ini`)
1. Crea `pytest.ini`
2. Define:
   - `testpaths = tests` para que pytest busque tests ah√≠
   - `addopts = -q` para salida m√°s corta

### 4) Crear `src/config.py`
1. Crea carpeta `src/` y archivo `config.py`
2. Define:
   - `BASE_URL` (por defecto: JSONPlaceholder)
   - `HTTP_TIMEOUT_SECONDS`
   - endpoints como `POSTS_ENDPOINT`
3. Importante: leer variables de entorno para que el c√≥digo sea flexible.

### 5) Crear los tests en `tests/`
1. Crea carpeta `tests/` y archivo `test_posts_api.py`
2. Escribe tests simples y claros:
   - `GET /posts` devuelve 200 y lista
   - `GET /posts/1` devuelve 200 y tiene `id`, `userId`, `title`, `body`
   - `GET /posts/999999` devuelve 404
   - `POST /posts` devuelve 201 y ‚Äúecho‚Äù del payload
3. Buenas pr√°cticas:
   - Un test = una intenci√≥n clara
   - Asserts cortos y con datos expl√≠citos
   - Reusar `BASE_URL` y `timeout` desde `src/config.py`

### 6) Ejecutar
1. Corre:

```powershell
pytest
```

2. Si quer√©s reporte:

```powershell
pytest --html=report.html --self-contained-html
```

### 7) Documentaci√≥n (para portfolio)
1. Agrega `README.md` (qu√© hace, c√≥mo correrlo)
2. Agrega `bug-reports/bug_report_template.md` para mostrar criterio QA

